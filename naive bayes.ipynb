{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes  \n",
    "## The Iris flowers Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u/>Classes</u>- types of Iris flower</h3><br/><br/>\n",
    "<table align='left'>\n",
    "    <tr><div style=\"text-align:left;font-size:125%\"><u>There are 3 possible flower types:</u></div></tr>\n",
    "    <tr><th>class 0 - Iris Setosa</th><th>class 1 - Iris Virginica</th><th>class 2 - Iris Versicolor</th></tr>\n",
    "    <tr>\n",
    "        <td><img src=\"./images/Iris-versicolor.jpg\" alt=\"Iris Versicolor\" style=\"width: 200px;text-align:left\"/></td>\n",
    "        <td><img src=\"./images/iris_setosa.jpg\" alt=\"Iris Setosa\" style=\"width: 200px;text-align:left\"/></td>\n",
    "        <td><img src=\"./images/iris_virginica.jpg\" alt=\"Iris Virginica\" style=\"width: 200px;text-align:left\"/></td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Feature Set</u></h3>\n",
    "<table align='left' width=\"200\">\n",
    "    <tr><td>\n",
    "        <img src=\"./images/iris_petal_sepal.png\" alt=\"Iris\" width=\"200\" align='left'/>\n",
    "    </td></tr>\n",
    "    <tr><td align='left'>\n",
    "        <div style=\"text-align:left;font-size:125%\"><u>Dataset includes 4 features</u>:</div><br/>\n",
    "        <ul style=\"list-style-type:circle;text-align:left;font-size:115%\">\n",
    "            <li>sepal-length</li>\n",
    "            <li>sepal-width</li>\n",
    "            <li>petal-length</li>\n",
    "            <li>petal-width</li>\n",
    "        </ul>\n",
    "    </td></tr>\n",
    "</table>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Loading datasets.\n",
    "The following cells perform 2 things:\n",
    "\n",
    "load the Iris dataset\n",
    "split the dataset to a train-set and a test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 Iris classes\n",
      "iris classes:\n",
      "[\"0 (representing 'setosa')\", \"1 (representing 'versicolor')\", \"2 (representing 'virginica')\"]\n",
      "\n",
      "There are 4 features in the feature set (each feature vector has a value for every feature)\n",
      "Feature names:\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "The dataset includes 150 instances (aka feature vectors)\n",
      "first few instances:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "\n",
      "first few corresponding categories:\n",
      "   target\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "# --------------------------------------------------------\n",
    "data_iris = datasets.load_iris()\n",
    "X_iris = pd.DataFrame(data_iris['data'], columns=data_iris['feature_names'])\n",
    "y_iris = pd.DataFrame(data_iris['target'], columns=['target'])\n",
    "# --------------------------------------------------------\n",
    "# display the iris class information:\n",
    "# --------------------------------------------------------\n",
    "classNames = data_iris['target_names']\n",
    "iris_classes = np.unique(y_iris.values)\n",
    "strClasses = [\"%d (representing '%s')\" %(iris_class,classNames[iris_class]) for iris_class in iris_classes]\n",
    "print ('There are %d Iris classes' %(len(strClasses)))\n",
    "print ('iris classes:')\n",
    "print(strClasses)\n",
    "# --------------------------------------------------------\n",
    "# display the feature information:\n",
    "# --------------------------------------------------------\n",
    "featureNames = [col for col in X_iris.columns]\n",
    "print ('\\nThere are %d features in the feature set (each feature vector has a value for every feature)' %(len(featureNames)))\n",
    "print('Feature names:')\n",
    "print(featureNames)\n",
    "# --------------------------------------------------------\n",
    "# display the first few rows of the dataset vectors:\n",
    "# --------------------------------------------------------\n",
    "print('\\nThe dataset includes %d instances (aka feature vectors)' %(X_iris.shape[0]))\n",
    "print('first few instances:')\n",
    "print(X_iris.head())\n",
    "print('\\nfirst few corresponding categories:')\n",
    "print(y_iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information after train-test split:\n",
      "The train-set includes 120 instances and 120 corresponding categories\n",
      "\n",
      "The test-set includes 30 instances and 30 corresponding categories\n",
      "\n",
      "First few rows of unified train-set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "22                4.6               3.6                1.0               0.2   \n",
       "15                5.7               4.4                1.5               0.4   \n",
       "65                6.7               3.1                4.4               1.4   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "42                4.4               3.2                1.3               0.2   \n",
       "\n",
       "    target  \n",
       "22       0  \n",
       "15       0  \n",
       "65       1  \n",
       "11       0  \n",
       "42       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "### The Following section splits the iris dataset directly from sklean\n",
    "# --------------------------------------------------------\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# display train-test split information\n",
    "# --------------------------------------------------------\n",
    "print ('Information after train-test split:')\n",
    "print('The train-set includes %d instances and %d corresponding categories\\n' %(X_train.shape[0],y_train.shape[0]))\n",
    "print('The test-set includes %d instances and %d corresponding categories\\n' %(X_test.shape[0],y_test.shape[0]))\n",
    "\n",
    "# --------------------------------------------------------\n",
    "## concatinate the X_train and y_train for Naive Bayes training:\n",
    "# --------------------------------------------------------\n",
    "train_set = pd.concat((X_train, y_train), axis=1)\n",
    "# --------------------------------------------------------\n",
    "if 'datasets' in sys.modules:\n",
    "    del (datasets)\n",
    "if 'train_test_split' in sys.modules:\n",
    "    del (train_test_split)\n",
    "sys_modules = list(sys.modules.keys())\n",
    "for mdl in sys_modules:\n",
    "    if mdl.startswith('sklearn.'):\n",
    "        del(sys.modules[mdl]) \n",
    "del (sklearn)\n",
    "if 'sklearn' in sys.modules:\n",
    "    del (sys.modules['sklearn'])\n",
    "# --------------------------------------------------------\n",
    "# Display the first few rows of the training-set:\n",
    "# --------------------------------------------------------\n",
    "print('First few rows of unified train-set:')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The naive bayes Classifier\n",
    "\n",
    "<img src=\"./images/bayes.PNG\" alt=\"Naive Bayes Classifier\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a (Guassian) Naive bayes model \n",
    "We perform the following during the training step:\n",
    "1. Calculate Priors\n",
    "2. Calculate Gaussian Likelihood 'mean' parameter\n",
    "3. Calculate Gaussian Likelihood 'std' parameter \n",
    "4. organize the call to the training steps in the 'fit' method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train step 1 - calculate category priors:\n",
    "for each class (0,1,2) you need to calculate the prior.<br/><br/>\n",
    "<b>prior(y=0)</b>=p(y=0)=count(y=0 in train-set)/count(number-of-instances in train-set)<br/><br/>\n",
    "<b> do this for each class (0,1,2) </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCategoryPriors(trainingSet):\n",
    "    \n",
    "    yTrain = trainingSet[['target']]\n",
    "    total=yTrain.shape[0]\n",
    "    uniqueClasses = np.unique(yTrain['target'].values)\n",
    "    helpLi=[]\n",
    "    li=[]\n",
    "    for m in uniqueClasses:\n",
    "        helpLi.append(0)\n",
    "        li.append(0)\n",
    "    \n",
    "    for i in yTrain['target']:\n",
    "        for x in uniqueClasses:\n",
    "            if i==uniqueClasses[x]:\n",
    "                helpLi[x]+=1\n",
    "    for x in range(len(li)):\n",
    "        li[x]=helpLi[x]/total\n",
    "    return li\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for expected class prior ...\n",
      "... 'calcCategoryPriors' test passed successfully :-)\n",
      "prior for category 0: 0.333333\n"
     ]
    }
   ],
   "source": [
    "arrPriors = calcCategoryPriors(train_set)\n",
    "priorClass_0 = arrPriors[0]\n",
    "print ('testing for expected class prior ...')\n",
    "assert int(priorClass_0*100)==33,'wrong prior for class-0'\n",
    "print (\"... 'calcCategoryPriors' test passed successfully :-)\")\n",
    "print ('prior for category 0: %f' %(priorClass_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calculate Gaussian Likelihood 'mean' parameter:\n",
    "for each feature calculate mean value for the feature in each for each of the class values (0,1,2) seperatly.<br/><br/>\n",
    "<b>for class 0 (y=0)</b> take the rows consisting 'target' value of 0, and calculate the mean <br/>\n",
    "To calculate mean use: dataframe[colName].mean() <br/><br/>\n",
    "<b>Do this for each feature for each class</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMeanLikelihood(trainingSet):\n",
    "    yTrain = trainingSet[['target']]\n",
    "    meandf=pd.DataFrame(index=np.unique(yTrain['target'].values),columns=trainingSet.columns)\n",
    "    meandf=meandf.drop(columns=['target'])\n",
    "    for i in range(len(meandf)):\n",
    "        meandf0=trainingSet.loc[trainingSet['target'].values == i]\n",
    "        meandf0=meandf0.drop(columns=['target'])\n",
    "        for col in meandf0.columns:\n",
    "            meandf.loc[i,col]=meandf0[col].mean()\n",
    "    return meandf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for expected mean likelihood estimation ...\n",
      "... 'calcMeanLikelihood' test passed successfully :-)\n",
      "likelihood for the mean of petal length for category 1 is estimated as: 4.241463\n"
     ]
    }
   ],
   "source": [
    "meanLiklihoodDf = calcMeanLikelihood(train_set)\n",
    "likelihood_petalLength_class1 = meanLiklihoodDf.iloc[1,2]\n",
    "print ('testing for expected mean likelihood estimation ...')\n",
    "assert int(likelihood_petalLength_class1*10)==42,'wrong mean likelihood estimation for petalLength_class1'\n",
    "print (\"... 'calcMeanLikelihood' test passed successfully :-)\")\n",
    "print ('likelihood for the mean of petal length for category 1 is estimated as: %f' %(likelihood_petalLength_class1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calculate Gaussian Likelihood 'std' parameter:\n",
    "for each feature calculate std value for the feature in each for each of the class values (0,1,2) seperatly.<br/><br/>\n",
    "<b>for class 0 (y=0)</b> take the rows consisting 'target' value of 0, and calculate the std <br/>\n",
    "To calculate std use: dataframe[colName].std() <br/><br/>\n",
    "<b>Do this for each feature for each class</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcStdLikelihood(trainingSet):\n",
    "    yTrain = trainingSet[['target']]\n",
    "    std=pd.DataFrame(index=np.unique(yTrain['target'].values),columns=trainingSet.columns)\n",
    "    std=std.drop(columns=['target'])\n",
    "    for i in range(len(std)):\n",
    "        std0=trainingSet.loc[trainingSet['target'].values == i]\n",
    "        std0=std0.drop(columns=['target'])\n",
    "        for col in std0.columns:\n",
    "            std.loc[i,col]=std0[col].std()\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing for expected std likelihood estimation ...\n",
      "... 'calcStdLikelihood' test passed successfully :-)\n",
      "likelihood for the std of petal length for category 1 is estimated as: 0.481132\n"
     ]
    }
   ],
   "source": [
    "stdLiklihoodDf = calcStdLikelihood(train_set)\n",
    "likelihood_petalLength_class1 = stdLiklihoodDf.iloc[1,2]\n",
    "print ('testing for expected std likelihood estimation ...')\n",
    "assert int(likelihood_petalLength_class1*10)==4,'wrong std likelihood estimation for petalLength_class1'\n",
    "print (\"... 'calcStdLikelihood' test passed successfully :-)\")\n",
    "print ('likelihood for the std of petal length for category 1 is estimated as: %f' %(likelihood_petalLength_class1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the fit method:\n",
    "<br>The fit method uses the previous 3 methods for a full (Gaussian) Naive Bayes model training step.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(trainingSet):\n",
    "    \"\"\"\n",
    "    1. Calculate the class priors of the training set, using the 'calcCategoryPriors' method.\n",
    "    2. Calculate the mean of the training set per feature per class, using the 'calcMeanLikelihood' method.\n",
    "    3. Calculate the std of the training set per feature per class, using the 'stdLiklihoodDf' method.\n",
    "    \"\"\"\n",
    "    arrPriors = calcCategoryPriors(trainingSet)\n",
    "    meanLiklihoodDf = calcMeanLikelihood(trainingSet)\n",
    "    stdLiklihoodDf = calcStdLikelihood(trainingSet)\n",
    "    \n",
    "    return meanLiklihoodDf, stdLiklihoodDf, arrPriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a class for a new example using the (Guassian) Naive bayes model \n",
    "We perform the following during the training step:\n",
    "1. Calculate Guassian likelihood probability, for a given feature value, mean and std\n",
    "2. Calculate a posteriori probabilities for each training example\n",
    "3. prdict class for for each training example, given a posteriori probabilities\n",
    "4. a full predict method using the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/bayes.PNG\" alt=\"Naive Bayes Classifier\" align='left'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the 'calcGaussianProb' method:\n",
    "The 'calcGaussianProb' method uses the training methods and returns the Gaussian probablilty <br/>\n",
    "of that feature value (for a specifc class).<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/gausianProb.PNG\" alt=\"Gausian likelihood probability\" align='left'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "given a specific feature value and the trained mean & std (per a specific class) \n",
    "We assume normal (Guassian distribution) and we return the density value \n",
    "or the Gaussian Probability for that given value\n",
    "Note: the input parameters are all numbers (scalars)\n",
    "\"\"\"\n",
    "def calcGaussianProb(xFeatureVal, mean, std):\n",
    "    exponent = np.exp(-((xFeatureVal-mean)**2 / (2 * std**2 )))\n",
    "    return (1 / ((2 * np.pi)**(1/2) * std)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the 'calcAposteriorProbs' method:\n",
    "The 'calcAposteriorProbs' method uses the training parameters to predict the a posteriori probability <br/>\n",
    "for every test instance, per class <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    1. Create a probability matrix to store the results\n",
    "    2. Update each label's probability using the Gaussian probability function\n",
    "\"\"\"\n",
    "def calcAposteriorProbs(XTest, arrTrainedClassPriors, dfTrainedMean, dfTrainedStd, categories):\n",
    "    numClasses = len(categories)\n",
    "    dfProbPerTestInstPerClass = pd.DataFrame(np.zeros((XTest.shape[0], numClasses)), columns=categories, index=XTest.index)\n",
    "    for category in categories:\n",
    "        classPrior = arrTrainedClassPriors[category]\n",
    "        dfProbPerTestInstPerClass[category]=classPrior\n",
    "        # Check for each row\n",
    "        for nRow in range(XTest.shape[0]):\n",
    "\n",
    "            # Multiply the current given probability by the newly calculated probability for the given event (feature)\n",
    "            for nCol in range(XTest.shape[1]):\n",
    "                xFeatureVal=XTest.iloc[nRow, nCol]\n",
    "                mean=dfTrainedMean.iloc[category,nCol]\n",
    "                std=dfTrainedStd.iloc[category,nCol]\n",
    "                gaussianProb = calcGaussianProb(xFeatureVal, mean, std)\n",
    "                # multiple the prior class probability with the gausian likelihood:\n",
    "                dfProbPerTestInstPerClass.iloc[nRow, category] *= gaussianProb\n",
    "    return dfProbPerTestInstPerClass            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the 'predictClasses' method:\n",
    "The 'predictClasses' method uses the calculated  a posteriori probabilites <br/>\n",
    "for every test instance, to calculate the most probable class for each test instance <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictClasses(df_probPerTestInstPerClass):\n",
    "    res=pd.Series(index=df_probPerTestInstPerClass.index)\n",
    "    for row in df_probPerTestInstPerClass.index:\n",
    "        res[row]=df_probPerTestInstPerClass.loc[row].idxmax()\n",
    "    print (res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the 'predict' method:\n",
    "The 'predict' method is a Guasian Naive Bayes classifier <br/>\n",
    "It uses the above methods to predict test instances <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(XTest, arrTrainedClassPriors, dfTrainedMean, dfTrainedStd, categories):\n",
    "    # 1. calculate a posterior probabities:\n",
    "    dfProbPerTestInstPerClass = calcAposteriorProbs(XTest, arrTrainedClassPriors, dfTrainedMean, dfTrainedStd, categories)\n",
    "\n",
    "    # 2. predict classes using the a posterior probabities:\n",
    "    results = predictClasses(dfProbPerTestInstPerClass)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compare how many predictions were correct (compare the y_hat to y)\n",
    "    \"\"\"\n",
    "    accuracy_score = pd.Series(y_true.values == y_pred.values).value_counts() * 100 / y_true.shape[0]\n",
    "    return accuracy_score.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73     1.0\n",
      "18     0.0\n",
      "118    2.0\n",
      "78     1.0\n",
      "76     1.0\n",
      "31     0.0\n",
      "64     1.0\n",
      "141    2.0\n",
      "68     1.0\n",
      "82     1.0\n",
      "110    2.0\n",
      "12     0.0\n",
      "36     0.0\n",
      "9      0.0\n",
      "19     0.0\n",
      "56     1.0\n",
      "104    2.0\n",
      "69     1.0\n",
      "55     1.0\n",
      "132    2.0\n",
      "29     0.0\n",
      "127    2.0\n",
      "26     0.0\n",
      "128    2.0\n",
      "131    2.0\n",
      "145    2.0\n",
      "108    2.0\n",
      "143    2.0\n",
      "45     0.0\n",
      "30     0.0\n",
      "dtype: float64\n",
      "Accuracy Score: 100.0\n"
     ]
    }
   ],
   "source": [
    "# --------------------- \n",
    "## The Following tests the the predict, using the accuracy function\n",
    "# --------------------- \n",
    "meanLiklihoodDf, stdLiklihoodDf, arrPriors=fit(train_set)\n",
    "iris_classes = np.unique(train_set['target'].values)\n",
    "y_hat = predict(X_test, arrPriors, meanLiklihoodDf, stdLiklihoodDf, iris_classes)\n",
    "accuracy_score = evaluate_accuracy(y_test['target'], y_hat)\n",
    "assert accuracy_score == 100, \"accuracy should be 100\"\n",
    "print(\"Accuracy Score: {}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
